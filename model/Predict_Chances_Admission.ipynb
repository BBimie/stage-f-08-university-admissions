{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: NEURAL NETWORK\n",
    "Used ANN as model with 3 hidden layers and Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "df_raw = pd.read_csv(\".../data/Admission_Predict_Ver1.1.csv\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the S.No. column as its not required\n",
    "df_raw = df_raw.drop(\"Serial No.\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GRE Score  TOEFL Score  University Rating         SOP       LOR   \\\n",
       "count  500.000000   500.000000         500.000000  500.000000  500.00000   \n",
       "mean   316.472000   107.192000           3.114000    3.374000    3.48400   \n",
       "std     11.295148     6.081868           1.143512    0.991004    0.92545   \n",
       "min    290.000000    92.000000           1.000000    1.000000    1.00000   \n",
       "25%    308.000000   103.000000           2.000000    2.500000    3.00000   \n",
       "50%    317.000000   107.000000           3.000000    3.500000    3.50000   \n",
       "75%    325.000000   112.000000           4.000000    4.000000    4.00000   \n",
       "max    340.000000   120.000000           5.000000    5.000000    5.00000   \n",
       "\n",
       "             CGPA    Research  Chance of Admit   \n",
       "count  500.000000  500.000000         500.00000  \n",
       "mean     8.576440    0.560000           0.72174  \n",
       "std      0.604813    0.496884           0.14114  \n",
       "min      6.800000    0.000000           0.34000  \n",
       "25%      8.127500    0.000000           0.63000  \n",
       "50%      8.560000    1.000000           0.72000  \n",
       "75%      9.040000    1.000000           0.82000  \n",
       "max      9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GRE', 'TOEFL', 'Univ_rating', 'SOP', 'LOR', 'CGPA', 'Research',\n",
       "       'Chance_of_admit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing column names\n",
    "new_cols = ['GRE', 'TOEFL','Univ_rating','SOP','LOR','CGPA','Research','Chance_of_admit']\n",
    "df_raw.columns=new_cols\n",
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "X = df_raw[new_cols[:7]]\n",
    "Y = df_raw['Chance_of_admit']\n",
    "X_train = X[:400]\n",
    "X_test = X[400:]\n",
    "Y_train = Y[:400]\n",
    "Y_test = Y[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>TOEFL</th>\n",
       "      <th>Univ_rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>316.807500</td>\n",
       "      <td>107.410000</td>\n",
       "      <td>3.087500</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.452500</td>\n",
       "      <td>8.598925</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.473646</td>\n",
       "      <td>6.069514</td>\n",
       "      <td>1.143728</td>\n",
       "      <td>1.006869</td>\n",
       "      <td>0.898478</td>\n",
       "      <td>0.596317</td>\n",
       "      <td>0.498362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.170000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.610000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GRE       TOEFL  Univ_rating         SOP         LOR  \\\n",
       "count  400.000000  400.000000   400.000000  400.000000  400.000000   \n",
       "mean   316.807500  107.410000     3.087500    3.400000    3.452500   \n",
       "std     11.473646    6.069514     1.143728    1.006869    0.898478   \n",
       "min    290.000000   92.000000     1.000000    1.000000    1.000000   \n",
       "25%    308.000000  103.000000     2.000000    2.500000    3.000000   \n",
       "50%    317.000000  107.000000     3.000000    3.500000    3.500000   \n",
       "75%    325.000000  112.000000     4.000000    4.000000    4.000000   \n",
       "max    340.000000  120.000000     5.000000    5.000000    5.000000   \n",
       "\n",
       "             CGPA    Research  \n",
       "count  400.000000  400.000000  \n",
       "mean     8.598925    0.547500  \n",
       "std      0.596317    0.498362  \n",
       "min      6.800000    0.000000  \n",
       "25%      8.170000    0.000000  \n",
       "50%      8.610000    1.000000  \n",
       "75%      9.062500    1.000000  \n",
       "max      9.920000    1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>TOEFL</th>\n",
       "      <th>Univ_rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.536150</td>\n",
       "      <td>0.550357</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.613125</td>\n",
       "      <td>0.576579</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.229473</td>\n",
       "      <td>0.216768</td>\n",
       "      <td>0.285932</td>\n",
       "      <td>0.251717</td>\n",
       "      <td>0.224619</td>\n",
       "      <td>0.191127</td>\n",
       "      <td>0.498362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.439103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.580128</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.725160</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GRE       TOEFL  Univ_rating         SOP         LOR  \\\n",
       "count  400.000000  400.000000   400.000000  400.000000  400.000000   \n",
       "mean     0.536150    0.550357     0.521875    0.600000    0.613125   \n",
       "std      0.229473    0.216768     0.285932    0.251717    0.224619   \n",
       "min      0.000000    0.000000     0.000000    0.000000    0.000000   \n",
       "25%      0.360000    0.392857     0.250000    0.375000    0.500000   \n",
       "50%      0.540000    0.535714     0.500000    0.625000    0.625000   \n",
       "75%      0.700000    0.714286     0.750000    0.750000    0.750000   \n",
       "max      1.000000    1.000000     1.000000    1.000000    1.000000   \n",
       "\n",
       "             CGPA    Research  \n",
       "count  400.000000  400.000000  \n",
       "mean     0.576579    0.547500  \n",
       "std      0.191127    0.498362  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.439103    0.000000  \n",
       "50%      0.580128    1.000000  \n",
       "75%      0.725160    1.000000  \n",
       "max      1.000000    1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the dataset using MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "myScaler = MinMaxScaler()\n",
    "X_cols = list(X_train.columns)\n",
    "X_train = myScaler.fit_transform(X_train)\n",
    "X_test = myScaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train, columns = X_cols)\n",
    "X_test = pd.DataFrame(X_test, columns = X_cols)\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE</th>\n",
       "      <th>TOEFL</th>\n",
       "      <th>Univ_rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance_of_admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827200</td>\n",
       "      <td>0.635376</td>\n",
       "      <td>0.613498</td>\n",
       "      <td>0.524679</td>\n",
       "      <td>0.825878</td>\n",
       "      <td>0.563398</td>\n",
       "      <td>0.810351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL</th>\n",
       "      <td>0.827200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649799</td>\n",
       "      <td>0.644410</td>\n",
       "      <td>0.541563</td>\n",
       "      <td>0.810574</td>\n",
       "      <td>0.467012</td>\n",
       "      <td>0.792228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Univ_rating</th>\n",
       "      <td>0.635376</td>\n",
       "      <td>0.649799</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728024</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.705254</td>\n",
       "      <td>0.427047</td>\n",
       "      <td>0.690132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>0.613498</td>\n",
       "      <td>0.644410</td>\n",
       "      <td>0.728024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.663707</td>\n",
       "      <td>0.712154</td>\n",
       "      <td>0.408116</td>\n",
       "      <td>0.684137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>0.524679</td>\n",
       "      <td>0.541563</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.663707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637469</td>\n",
       "      <td>0.372526</td>\n",
       "      <td>0.645365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>0.825878</td>\n",
       "      <td>0.810574</td>\n",
       "      <td>0.705254</td>\n",
       "      <td>0.712154</td>\n",
       "      <td>0.637469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501311</td>\n",
       "      <td>0.882413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>0.563398</td>\n",
       "      <td>0.467012</td>\n",
       "      <td>0.427047</td>\n",
       "      <td>0.408116</td>\n",
       "      <td>0.372526</td>\n",
       "      <td>0.501311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance_of_admit</th>\n",
       "      <td>0.810351</td>\n",
       "      <td>0.792228</td>\n",
       "      <td>0.690132</td>\n",
       "      <td>0.684137</td>\n",
       "      <td>0.645365</td>\n",
       "      <td>0.882413</td>\n",
       "      <td>0.545871</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      GRE     TOEFL  Univ_rating       SOP       LOR  \\\n",
       "GRE              1.000000  0.827200     0.635376  0.613498  0.524679   \n",
       "TOEFL            0.827200  1.000000     0.649799  0.644410  0.541563   \n",
       "Univ_rating      0.635376  0.649799     1.000000  0.728024  0.608651   \n",
       "SOP              0.613498  0.644410     0.728024  1.000000  0.663707   \n",
       "LOR              0.524679  0.541563     0.608651  0.663707  1.000000   \n",
       "CGPA             0.825878  0.810574     0.705254  0.712154  0.637469   \n",
       "Research         0.563398  0.467012     0.427047  0.408116  0.372526   \n",
       "Chance_of_admit  0.810351  0.792228     0.690132  0.684137  0.645365   \n",
       "\n",
       "                     CGPA  Research  Chance_of_admit  \n",
       "GRE              0.825878  0.563398         0.810351  \n",
       "TOEFL            0.810574  0.467012         0.792228  \n",
       "Univ_rating      0.705254  0.427047         0.690132  \n",
       "SOP              0.712154  0.408116         0.684137  \n",
       "LOR              0.637469  0.372526         0.645365  \n",
       "CGPA             1.000000  0.501311         0.882413  \n",
       "Research         0.501311  1.000000         0.545871  \n",
       "Chance_of_admit  0.882413  0.545871         1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the Correlation\n",
    "df_raw.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Validation Split\n",
    "X_t = X_train[:300]\n",
    "X_val = X_train[300:400]\n",
    "Y_t = Y_train[:300]\n",
    "Y_val = Y_train[300:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELLING\n",
    "\n",
    "training_epochs = 50\n",
    "learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8)                 64        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=7, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4,activation='sigmoid'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate),metrics=[keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0262 - root_mean_squared_error: 0.1618 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1347\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0160 - root_mean_squared_error: 0.1266 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1119\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0134 - root_mean_squared_error: 0.1159 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0105 - root_mean_squared_error: 0.1023 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0809\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0081 - root_mean_squared_error: 0.0899 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0730\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0065 - root_mean_squared_error: 0.0805 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0063 - root_mean_squared_error: 0.0795 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0057 - root_mean_squared_error: 0.0755 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0061 - root_mean_squared_error: 0.0781 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0745\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0052 - root_mean_squared_error: 0.0724 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0052 - root_mean_squared_error: 0.0720 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0052 - root_mean_squared_error: 0.0719 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0051 - root_mean_squared_error: 0.0714 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0051 - root_mean_squared_error: 0.0717 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0627\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0049 - root_mean_squared_error: 0.0701 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0049 - root_mean_squared_error: 0.0697 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0049 - root_mean_squared_error: 0.0700 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0049 - root_mean_squared_error: 0.0703 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0051 - root_mean_squared_error: 0.0716 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0046 - root_mean_squared_error: 0.0677 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0044 - root_mean_squared_error: 0.0666 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0044 - root_mean_squared_error: 0.0662 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0595\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0045 - root_mean_squared_error: 0.0671 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0045 - root_mean_squared_error: 0.0669 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0045 - root_mean_squared_error: 0.0673 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0044 - root_mean_squared_error: 0.0664 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0045 - root_mean_squared_error: 0.0669 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0047 - root_mean_squared_error: 0.0688 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0042 - root_mean_squared_error: 0.0648 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0580\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0042 - root_mean_squared_error: 0.0648 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0045 - root_mean_squared_error: 0.0670 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0044 - root_mean_squared_error: 0.0660 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0043 - root_mean_squared_error: 0.0657 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0577\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0044 - root_mean_squared_error: 0.0664 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0043 - root_mean_squared_error: 0.0654 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0042 - root_mean_squared_error: 0.0645 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0688\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0044 - root_mean_squared_error: 0.0663 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0600\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0049 - root_mean_squared_error: 0.0699 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0583\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0639 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0040 - root_mean_squared_error: 0.0632 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0578\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0041 - root_mean_squared_error: 0.0638 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0593\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0041 - root_mean_squared_error: 0.0642 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.0042 - root_mean_squared_error: 0.0646 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0639 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0041 - root_mean_squared_error: 0.0640 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.0040 - root_mean_squared_error: 0.0629 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0571\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "\n",
    "results = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs= training_epochs,\n",
    "    batch_size = 16,\n",
    "    validation_data=(X_val, Y_val.T)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the training rmse scores vs epochs\n",
    "plt.plot(results.history['root_mean_squared_error'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for predictions is:  0.04565008514486151\n",
      "\n",
      "The Predicted values are:\n",
      "[0.6162628], [0.67533267], [0.77610195], [0.89181495], [0.57374465], [0.51280063], [0.6495708], [0.6288755], [0.5972732], [0.5744407], [0.5557774], [0.55609256], [0.5940115], [0.6036976], [0.74703515], [0.78988755], [0.62009734], [0.5490519], [0.6812684], [0.6518873], [0.51136875], [0.80878115], [0.83147585], [0.9317125], [0.91189706], [0.9207494], [0.74729824], [0.7553782], [0.7527343], [0.91467065], [0.66902095], [0.7733575], [0.87234783], [0.7595798], [0.6297724], [0.6198143], [0.61617225], [0.65106094], [0.74929875], [0.69154024], [0.5445621], [0.7769099], [0.9097123], [0.8925196], [0.8970096], [0.90352297], [0.9224291], [0.8084433], [0.77054316], [0.7731388], [0.81044567], [0.8799865], [0.9151473], [0.76592904], [0.6425277], [0.5552824], [0.54240894], [0.49324957], [0.69485825], [0.88947546], [0.76745], [0.5988219], [0.6074654], [0.59678996], [0.48446703], [0.657165], [0.7527737], [0.7805424], [0.82419103], [0.8730706], [0.880093], [0.6677258], [0.90465724], [0.6537677], [0.6159384], [0.54581875], [0.59150213], [0.6054926], [0.74463844], [0.8396963], [0.7821499], [0.7190503], [0.8284787], [0.5699945], [0.6480977], [0.69277894], [0.66442776], [0.8285679], [0.7773993], [0.71836746], [0.7025634], [0.55660963], [0.6138199], [0.5579393], [0.62871957], [0.8771624], [0.93931365], [0.9312396], [0.72174895], [0.819756], "
     ]
    }
   ],
   "source": [
    "# RMSE Score for Test Data (last 100 Entries of Data)\n",
    "\n",
    "y_pred = predictions\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE for predictions is: \",rmse)\n",
    "print(\"\\nThe Predicted values are:\")\n",
    "for i in predictions:\n",
    "    print(i, end = ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
